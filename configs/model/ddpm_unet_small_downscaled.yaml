name: ddpm_unet
type: function
key: 4269
size: small
parameters: 
  img_h: 32
  img_w: 32
  batch_size: 3
  momentum: 0.99
  eps: 0.00001
  dropout_p: 0.1
  upsampling_factor: 2
  downsampling_factor: 2
  time_embedding_dims: 32
  inference: False
  model_parameter_association:
    - [1,0,0,0] # 0 # conv,skip_linear,time_embed_linear,attention_linear
    - [4,2,2,0] # 1
    - [4,2,2,8] # 2
    - [6,3,3,12] # 10
    - [6,3,3,0] # 11
    - [1,0,0,0] # 12
  embedding_parameters:
    - [32,128] # Linear
    - [128,128] # Linear
  conv_channels: 
    - [3,32]   #  0 # 32x32
    - [32,32] # 1  # 32x32
    - [32,32] # 1  # 32x32
    - [32,32] # 1  # 32x32
    - [32,32] # 1  # 32x32
    - [32,64]  # 2 # 16x16
    - [64,64]  # 2 # 16x16
    - [64,64]  # 2 # 16x16
    - [64,64]  # 2 # 16x16
    - [128,64]  # 10 res in 256+512 = 768
    - [64,64]  # 10
    - [128,64]  # 10 res in 256+256 = 512
    - [64,64]  # 10
    - [96,64]  # 10 res in 128+256 = 384
    - [64,64]  # 10
    - [96,32] # 11 res in 128+256 = 384
    - [32,32] # 11
    - [64,32] # 11 res in 128+128 = 256
    - [32,32] # 11
    - [64,32] # 11 res in 128+128 = 256
    - [32,32] # 11
    - [32,3] # 12
  skip_linear:
    - [32,32] # 1
    - [32,32] # 1
    - [64,64] #  2
    - [64,64] #  2
    - [64,64] # 10
    - [64,64] # 10
    - [64,64] # 10
    - [32,32] #  11
    - [32,32] #  11
    - [32,32] #  11
  time_embed_linear:
    - [128,32] # 1
    - [128,32] # 1
    - [128,64] #  2
    - [128,64] #  2
    - [128,64] # 10
    - [128,64] # 10
    - [128,64] # 10
    - [128,32] #  11
    - [128,32] #  11
    - [128,32] #  11
  attention_linear:
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
    - [64,64] # 1 q1
  kernel_sizes: 
    - [3,3]   #  0 # 32x32
    - [3,3] # 1  # 32x32
    - [3,3] # 1  # 32x32
    - [3,3] # 1  # 32x32
    - [3,3] # 1  # 32x32
    - [3,3]  # 2 # 16x16
    - [3,3]  # 2 # 16x16
    - [3,3]  # 2 # 16x16
    - [3,3]  # 2 # 16x16
    - [3,3] # 3  # 8x8
    - [3,3] # 3  # 8x8
    - [3,3] # 3  # 8x8
    - [3,3] # 3  # 8x8
    - [3,3]  # 4 # 4x4  
    - [3,3]  # 4 # 4x4
    - [3,3]  # 4 # 4x4  
    - [3,3]  # 4 # 4x4
    - [3,3] # 5  # 4x4
    - [3,3] # 5  # 4x4
    - [3,3]  # 7 # 4x4
    - [3,3]  # 7 # 4x4
    - [3,3] # 8 res in 512+512 = 1024
    - [3,3]  # 8
    - [3,3] # 8 res in 512+512 = 1024
    - [3,3]  # 8
    - [3,3] # 8 res in 512+512 = 1024
    - [3,3]  # 8
    - [3,3]  # 9 res in 512+512 = 1024
    - [3,3]   # 9
    - [3,3]  # 9 res in 512+512 = 1024
    - [3,3]   # 9
    - [3,3]   # 9 res in 256+512 = 768
    - [3,3]   # 9
    - [3,3]  # 10 res in 256+512 = 768
    - [3,3]  # 10
    - [3,3]  # 10 res in 256+256 = 512
    - [3,3]  # 10
    - [3,3]  # 10 res in 128+256 = 384
    - [3,3]  # 10
    - [3,3] # 11 res in 128+256 = 384
    - [3,3] # 11
    - [3,3] # 11 res in 128+128 = 256
    - [3,3] # 11
    - [3,3] # 11 res in 128+128 = 256
    - [3,3] # 11 
    - [3,3] # 12
 